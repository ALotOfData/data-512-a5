{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pdf data extraction\n",
    "\n",
    "## Goal\n",
    "\n",
    "This notebook contains the code to extract text from the unzipped pdf files obtained from the [HSPCI website](https://intelligence.house.gov/social-media-content/social-media-advertisements.htm).\n",
    "\n",
    "Before running the code below:\n",
    "\n",
    "1. Place the unzipped folders under the raw_data directory\n",
    "2. Install the [pdftotext](https://www.xpdfreader.com/pdftotext-man.html) terminal command.\n",
    "\n",
    "The code will create two outputs:\n",
    "\n",
    "1. raw.csv which is used in the data_cleaning notebook\n",
    "2. txt_files/ directory containing the raw text extracted from the first page of each pdf files.\n",
    "\n",
    "## Extracting text from pdfs\n",
    "\n",
    "To extract text from pdfs we look for files ending in `.pdf` under the raw_data folder. We call the pdftotext utility to extract text from the first page of each pdfs and output the files under the same name in a new txt_files fodler and change the extension to txt.\n",
    "\n",
    "Note that executing this will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "input_path = '../raw_data/'\n",
    "output_path = '../raw_data/txt_files/'\n",
    "\n",
    "# Get all pdf files under path\n",
    "for root, directories, files in os.walk(input_path):\n",
    "    for file in files:\n",
    "        if \".pdf\" in file:\n",
    "            # Create file paths\n",
    "            pdf_file_path = os.path.join(root, file)\n",
    "            pdf_file_path = pdf_file_path.replace('(', '\\(')\n",
    "            pdf_file_path = pdf_file_path.replace(')', '\\)')\n",
    "            txt_file_path = pdf_file_path[:-3] + 'txt'\n",
    "\n",
    "            # You will need to have the pdftotext command line command available\n",
    "            pdf_to_text_cmd = f'pdftotext -l 1 {pdf_file_path}'\n",
    "            os.system(pdf_to_text_cmd)\n",
    "\n",
    "            mv_cmd = f'mv {txt_file_path} {output_path}'\n",
    "            os.system(mv_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting information from pdfs\n",
    "\n",
    "The image below shows the format of the txt files we extracted.\n",
    "\n",
    "![Russian ad description](../assets/pictures/ad_preview.png)\n",
    "\n",
    "To extract information found on each line from the text we will need many regular expressions. They are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "regex_dict = {\n",
    "    'ad_line_start': r\"^Ad\\s+\",\n",
    "    # Sometimes pdf files wrote Id with an 1, l or I character the spacing was also inconsistent\n",
    "    'ad_id': r\"^A\\s*d\\s*(I|l|1)\\s*D\\s*(?P<ad_id>[0-9]*)\",\n",
    "    'ad_text': r\"^A\\s*d\\s*Text\\s*\",\n",
    "    'ad_landing_page': r\"^Ad\\s+Landing\\s+Page\\s+(?P<ad_landing_page>.*)\",\n",
    "    'ad_targeting': r\"^Ad\\s*Targeting\\s*(?P<ad_targeting>.*)\",\n",
    "    'ad_impressions': r\"^Ad\\s*Impressions\\s*:?\\s*(?P<ad_impressions>.*)\",\n",
    "    'ad_clicks': r\"^Ad\\s*Clicks\\s*:?\\s*(?P<ad_clicks>.*)\",\n",
    "    'ad_spend': r\"^Ad\\s*spend\\s*:?\\s*(?P<ad_spend>.*)\",\n",
    "    'ad_creation_date': r\"^Ad\\s*creation\\s*date\\s*:?\\s*(?P<ad_creation_date>.*)\",\n",
    "    'ad_end_date': r\"^Ad\\s*end\\s*date\\s*:?\\s*(?P<ad_end_date>.*)\"\n",
    "}\n",
    "\n",
    "# Order of these entries is important!\n",
    "ordered_targeting_topics_regex = {\n",
    "    'custom_audience': r'^custom\\s*audience\\s*:?\\s*(?P<custom_audience>.*)',\n",
    "    'location': r'^location\\s*:?\\s*(?P<location>.*)',\n",
    "    'interests': r'^interests\\s*:?\\s*(?P<interests>.*)',\n",
    "    'excluded_connections': r'^excluded\\s*connections\\s*:?\\s*(?P<excluded_connections>.*)',\n",
    "    'age': r'^age\\s*:?\\s*(?P<age>.*)',\n",
    "    'language': r'^language\\s*:?\\s*(?P<language>.*)',\n",
    "    'placements': r'^placements\\s*:?\\s*(?P<placements>.*)',\n",
    "    'people_who_match': r'^people\\s*who\\s*match\\s*:?\\s*(?P<people_who_match>.*)'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define a few parsing functions before we can parse our ad text files. We first create a function which can parse information contained in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a key from the regex_dict, an array of lines from the file, the current line index\n",
    "# and a dicionary to log parsing errors, use the appropriate regex to obtain the value.\n",
    "#\n",
    "# Returns the extracted value or None and the next line to parse (remains the same line if no value was found)\n",
    "def extract_inline(regex_key, file_name, lines, line_index, parse_errors_file_dict):\n",
    "    # Get the line from file\n",
    "    line = lines[line_index]\n",
    "    \n",
    "    # Look for a match (case insensitive)\n",
    "    matches = re.search(regex_dict[regex_key], line, flags=re.IGNORECASE)\n",
    "    \n",
    "    to_extract = None\n",
    "    if matches is not None:\n",
    "        group_dict = matches.groupdict()\n",
    "        to_extract = group_dict.get(regex_key)\n",
    "\n",
    "    # Add to fail to parse dictionary if regex was not comprehensive\n",
    "    if to_extract is None:\n",
    "        parse_errors_file_dict[regex_key].append(file_name)\n",
    "        new_line_index = line_index\n",
    "    else:\n",
    "        new_line_index = line_index + 1\n",
    "\n",
    "    return to_extract, new_line_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ad text can be on multiple lines so we create a function which iterates through lines from the current file until we find the next line starting with 'Ad '."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the name of the file, an array of lines from the file, the current line index\n",
    "# and a dicionary to log parsing errors it extracts the Ad Text value.\n",
    "#\n",
    "# Returns the extracted value or None and the next line to parse (remains the same line if no value was found)\n",
    "def extract_ad_text(file_name, lines, line_index, parse_errors_file_dict):\n",
    "    ad_text = None\n",
    "    line = lines[line_index]\n",
    "\n",
    "    # Search for line containing 'Ad Text'\n",
    "    matches = re.search(regex_dict['ad_text'], line, flags=re.IGNORECASE)\n",
    "    \n",
    "    # If the line contains 'Ad Text'\n",
    "    if matches is not None and matches.span() is not (-1, -1):\n",
    "        (_, end) = matches.span()\n",
    "        # Grab information for this first line after 'Ad Text'\n",
    "        ad_text_array = [line[end:]]\n",
    "        \n",
    "        # Move on to the next line\n",
    "        new_line_index = line_index + 1\n",
    "        \n",
    "        # As long as we have not reached the end of the file's lines\n",
    "        while new_line_index < len(lines):\n",
    "            # Get the current line\n",
    "            line = lines[new_line_index]\n",
    "            \n",
    "            # Check for 'Ad ' signaling the start of a different field to parse\n",
    "            matches = re.search(regex_dict['ad_line_start'], line, flags=re.IGNORECASE)\n",
    "            if matches is not None:\n",
    "                # We found the end of the Ad Text stop\n",
    "                break\n",
    "            else:\n",
    "                ad_text_array.append(line)\n",
    "                new_line_index += 1\n",
    "        \n",
    "        # Join lines together with space\n",
    "        ad_text = ''.join(ad_text_array)\n",
    "\n",
    "    # If no ad_text was found add to the parsing error dictionary\n",
    "    if ad_text is None:\n",
    "        parse_errors_file_dict['ad_text'].append(file_name)\n",
    "        new_line_index = line_index\n",
    "\n",
    "    return ad_text, new_line_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting information for the Ad Targeting section is a bit more complex, first we use a function to extract the lines which are part of the ad_targeting section. We then extract a dictionary of the different targeting topics and assigned them. Finally we return the parsed variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the name of the file, an array of lines from the file, the current line index\n",
    "# and a dicionary to log parsing errors it extracts all ad targeting values\n",
    "#\n",
    "# Returns the extracted value or None and the next line to parse (remains the same line if no value was found)\n",
    "def extract_ad_targeting(file_name, lines, line_index, parse_errors_file_dict):\n",
    "    # Step 1) get all targeting related lines and next line\n",
    "    targeting_lines, next_line_index = extract_targeting_lines(lines, line_index)\n",
    "\n",
    "    # Step 2) get topic dictionary with list of target per topic\n",
    "    topic_dictionary = get_topic_dictionary(targeting_lines) if targeting_lines else dict()\n",
    "\n",
    "    # Step 3) assign topic dictionary entry to variables (get defaults to None)\n",
    "    ad_targeting_custom_audience = topic_dictionary.get('custom_audience')\n",
    "    ad_targeting_location = topic_dictionary.get('location')\n",
    "    ad_targeting_interests = topic_dictionary.get('interests')\n",
    "    ad_targeting_excluded_connections = topic_dictionary.get('excluded_connections')\n",
    "    ad_targeting_age = topic_dictionary.get('age')\n",
    "    ad_targeting_language = topic_dictionary.get('language')\n",
    "    ad_targeting_placements = topic_dictionary.get('placements')\n",
    "    ad_targeting_people_who_match = topic_dictionary.get('people_who_match')\n",
    "\n",
    "    return (ad_targeting_custom_audience,\n",
    "            ad_targeting_location,\n",
    "            ad_targeting_interests,\n",
    "            ad_targeting_excluded_connections,\n",
    "            ad_targeting_age,\n",
    "            ad_targeting_language,\n",
    "            ad_targeting_placements,\n",
    "            ad_targeting_people_who_match,\n",
    "            next_line_index)\n",
    "\n",
    "# Given the file's lines and the current line\n",
    "# Returns an array of lines for the ad targeting and the appropriate next line to analyze.\n",
    "def extract_targeting_lines(lines, line_index):\n",
    "    targeting_lines = []\n",
    "\n",
    "    # Step 1) check that the current line is the targeting line\n",
    "    matches = re.search(regex_dict['ad_targeting'], lines[line_index], flags=re.IGNORECASE)\n",
    "    if matches is None:\n",
    "        return None, line_index\n",
    "    else:\n",
    "        first_line = matches.groupdict()['ad_targeting']\n",
    "        targeting_lines.append(first_line)\n",
    "        line_index += 1\n",
    "\n",
    "    # Step 2) get lines\n",
    "    next_line_index = line_index\n",
    "    match_found = False\n",
    "    \n",
    "    # While we have not reached the end of the file's line and not found a match with \n",
    "    # ad_impressions which follows ad targeting...\n",
    "    while next_line_index < len(lines) and not match_found:\n",
    "        line = lines[next_line_index]\n",
    "        matches = re.search(regex_dict['ad_impressions'], line, flags=re.IGNORECASE)\n",
    "\n",
    "        if matches is not None:\n",
    "            match_found = True\n",
    "        else:\n",
    "            targeting_lines.append(line)\n",
    "            next_line_index += 1\n",
    "\n",
    "    if not match_found:\n",
    "        targeting_lines = None\n",
    "        parse_errors_file_dict['ad_targeting'].append(file_name)\n",
    "\n",
    "    return targeting_lines, next_line_index if match_found else line_index\n",
    "\n",
    "# Using the lines found for targeting, extract each topic\n",
    "# and return a dictionary containing the successfully extracted values\n",
    "def get_topic_dictionary(targeting_lines):\n",
    "    # Create a copy of the regexes for targeting\n",
    "    topic_regex = copy.deepcopy(ordered_targeting_topics_regex)\n",
    "    \n",
    "    # Create an empty dictionary for all matches found\n",
    "    topic_text_dictionary = {}\n",
    "    \n",
    "    # For each targeting lines\n",
    "    current_topic = None\n",
    "    for i in range(len(targeting_lines)):\n",
    "        # Get current line\n",
    "        line = targeting_lines[i]\n",
    "        \n",
    "        for topic, regex in topic_regex.items():\n",
    "            matches = re.search(regex, line, flags=re.IGNORECASE)\n",
    "\n",
    "            if matches and matches.groupdict():\n",
    "                # current_topic can match until new topic is found\n",
    "                current_topic = topic\n",
    "\n",
    "                # remove topic name from value using groups\n",
    "                # we use this as a marker to know if we have already covered a topic\n",
    "                group_dict = matches.groupdict()\n",
    "                line = group_dict.get(topic)\n",
    "\n",
    "                # Once a topic is found it is removed\n",
    "                topic_regex.pop(topic)\n",
    "                break\n",
    "\n",
    "        if current_topic is None:\n",
    "            return None\n",
    "\n",
    "        # If we have a current_topic we are matching\n",
    "        if current_topic in topic_text_dictionary:\n",
    "            # It is on multiple line continue to append\n",
    "            topic_text_dictionary[current_topic] += (' ' + line.replace('\\n', ''))\n",
    "        else:\n",
    "            # It is the first time we've match add the line\n",
    "            topic_text_dictionary[current_topic] = line if line is not None else ''\n",
    "\n",
    "    return topic_text_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all the functions defined above, we create a function that can fully parse lines of a ad txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the name of ad txt file, its path and a dictionary to log parsing errors,\n",
    "# extract as many fields as possible from the raw text.\n",
    "def row_from_file(file_name, file_path, parse_errors_file_dict):\n",
    "    # Open the txt file\n",
    "    with open(file_path, 'r') as ad_file:\n",
    "        # Read each line in an array\n",
    "        lines = ad_file.readlines()\n",
    "        \n",
    "        # If the file is empty add a file empty error\n",
    "        if lines is None and len(lines) == 0:\n",
    "            parse_errors_file_dict['empty'].append(file_path)\n",
    "\n",
    "        # Start by looking at the first line\n",
    "        line_index = 0\n",
    "\n",
    "        # ad_id\n",
    "        (ad_id, line_index) = extract_inline('ad_id', file_name, lines, line_index, parse_errors_file_dict)\n",
    "\n",
    "        # ad_text\n",
    "        (ad_text, line_index) = extract_ad_text(file_name, lines, line_index, parse_errors_file_dict)\n",
    "\n",
    "        # ad_landing_page\n",
    "        (ad_landing_page, line_index) = extract_inline('ad_landing_page', file_name, lines, line_index,\n",
    "                                                       parse_errors_file_dict)\n",
    "\n",
    "        # ad_targeting (all ad_targeting is extracted here\n",
    "        (ad_targeting_custom_audience,\n",
    "         ad_targeting_location,\n",
    "         ad_targeting_interests,\n",
    "         ad_targeting_excluded_connections,\n",
    "         ad_targeting_age,\n",
    "         ad_targeting_language,\n",
    "         ad_targeting_placements,\n",
    "         ad_targeting_people_who_match,\n",
    "         line_index) = extract_ad_targeting(\n",
    "            file_name,\n",
    "            lines,\n",
    "            line_index,\n",
    "            parse_errors_file_dict)\n",
    "\n",
    "        # ad_impressions\n",
    "        (ad_impressions, line_index) = extract_inline('ad_impressions', file_name, lines, line_index,\n",
    "                                                      parse_errors_file_dict)\n",
    "\n",
    "        # ad_clicks\n",
    "        (ad_clicks, line_index) = extract_inline('ad_clicks', file_name, lines, line_index, parse_errors_file_dict)\n",
    "\n",
    "        # ad_spend\n",
    "        (ad_spend, line_index) = extract_inline('ad_spend', file_name, lines, line_index, parse_errors_file_dict)\n",
    "\n",
    "        # ad_creation_date\n",
    "        (ad_creation_date, line_index) = extract_inline('ad_creation_date', file_name, lines, line_index,\n",
    "                                                        parse_errors_file_dict)\n",
    "\n",
    "        # ad_end_date\n",
    "        (ad_end_date, line_index) = extract_inline('ad_end_date', file_name, lines, line_index, parse_errors_file_dict)\n",
    "\n",
    "    return [file_name,\n",
    "            ad_id,\n",
    "            ad_text,\n",
    "            ad_landing_page,\n",
    "            ad_targeting_custom_audience,\n",
    "            ad_targeting_location,\n",
    "            ad_targeting_interests,\n",
    "            ad_targeting_excluded_connections,\n",
    "            ad_targeting_age,\n",
    "            ad_targeting_language,\n",
    "            ad_targeting_placements,\n",
    "            ad_targeting_people_who_match,\n",
    "            ad_impressions,\n",
    "            ad_clicks,\n",
    "            ad_spend,\n",
    "            ad_creation_date,\n",
    "            ad_end_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below opens the txt versions of the ads and extracts the information using the row_from_file function explained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../raw_data/txt_files/'\n",
    "\n",
    "all_rows = []\n",
    "parse_errors_file_dict = {\n",
    "    'ad_id': [],\n",
    "    'ad_text': [],\n",
    "    'ad_landing_page': [],\n",
    "    'ad_targeting': [],\n",
    "    'ad_targeting_custom_audience': [],\n",
    "    'ad_targeting_location': [],\n",
    "    'ad_targeting_interests': [],\n",
    "    'ad_targeting_excluded_connections': [],\n",
    "    'ad_targeting_age': [],\n",
    "    'ad_targeting_language': [],\n",
    "    'ad_targeting_placements': [],\n",
    "    'ad_targeting_people_who_match': [],\n",
    "    'ad_impressions': [],\n",
    "    'ad_clicks': [],\n",
    "    'ad_spend': [],\n",
    "    'ad_creation_date': [],\n",
    "    'ad_end_date': [],\n",
    "    'empty': []\n",
    "}\n",
    "\n",
    "for root, directories, files in os.walk(input_path):\n",
    "    for file_name in files:\n",
    "        if \".txt\" in file_name:\n",
    "            txt_file_path = os.path.join(root, file_name)\n",
    "            row_array = row_from_file(file_name, txt_file_path, parse_errors_file_dict)\n",
    "            all_rows.append(row_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally take rows and output them to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_rows, columns=[\n",
    "    'file_name',\n",
    "    'ad_id',\n",
    "    'ad_text',\n",
    "    'ad_landing_page',\n",
    "    'ad_targeting_custom_audience',\n",
    "    'ad_targeting_location',\n",
    "    'ad_targeting_interests',\n",
    "    'ad_targeting_excluded_connections',\n",
    "    'ad_targeting_age',\n",
    "    'ad_targeting_language',\n",
    "    'ad_targeting_placements',\n",
    "    'ad_targeting_people_who_match',\n",
    "    'ad_impressions',\n",
    "    'ad_clicks',\n",
    "    'ad_spend',\n",
    "    'ad_creation_date',\n",
    "    'ad_end_date'\n",
    "])\n",
    "df.to_csv('../raw_data/raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next notebook is [data_cleaning](data_cleaning.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
